[32m2024-07-12 02:12:22 +0400[0m - dagster - [34mDEBUG[0m - __ASSET_JOB_0 - 58fa64e0-8aa1-4038-8054-63ac3472f377 - 35153 - LOGS_CAPTURED - Started capturing logs in process (pid: 35153).
[32m2024-07-12 02:12:22 +0400[0m - dagster - [34mDEBUG[0m - __ASSET_JOB_0 - 58fa64e0-8aa1-4038-8054-63ac3472f377 - 35153 - load_daily_partition - STEP_START - Started execution of step "load_daily_partition".
[32m2024-07-12 02:12:23 +0400[0m - dagster - [34mERROR[0m - [31m__ASSET_JOB_0 - 58fa64e0-8aa1-4038-8054-63ac3472f377 - 35153 - load_daily_partition - STEP_FAILURE - Execution of step "load_daily_partition" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "load_daily_partition"::

pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/home/user/Desktop/ameria/v2/data/green_tripdata.parquet.

Stack Trace:
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 468, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/home/user/Desktop/ameria/v2/dagster_module/assets.py", line 53, in load_daily_partition
    df = spark.read.parquet(green_data_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 544, in parquet
    return self._df(self._jreader.parquet(_to_seq(self._spark._sc, paths)))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None

The above exception occurred during handling of the following exception:
py4j.protocol.Py4JJavaError: An error occurred while calling o27.parquet.
: org.apache.spark.sql.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/home/user/Desktop/ameria/v2/data/green_tripdata.parquet.
	at org.apache.spark.sql.errors.QueryCompilationErrors$.dataPathNotExistError(QueryCompilationErrors.scala:1500)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:757)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)


Stack Trace:
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
[0m
