[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - 51214 - LOGS_CAPTURED - Started capturing logs in process (pid: 51214).
[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - 51214 - load_daily_partition - STEP_START - Started execution of step "load_daily_partition".
[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - 51214 - load_daily_partition - ASSET_MATERIALIZATION - Partitioned data for 2024-02-01
[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - 51214 - load_daily_partition - STEP_OUTPUT - Yielded output "result" of type "Any". (Type check passed).
[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - load_daily_partition - Writing file at: /home/user/Desktop/ameria/v2/dagster_module/storage/load_daily_partition/2024-02-01 using PickledObjectFilesystemIOManager...
[32m2024-07-12 02:58:20 +0400[0m - dagster - [34mERROR[0m - [31m__ephemeral_asset_job__ - 01cdbac2-8f93-4d0e-9e5c-9fafd342fa71 - 51214 - load_daily_partition - STEP_FAILURE - Execution of step "load_daily_partition" failed.

dagster._core.errors.DagsterExecutionHandleOutputError: Error occurred while handling output "result" of step "load_daily_partition"::

pyspark.errors.exceptions.base.PySparkRuntimeError: [CONTEXT_ONLY_VALID_ON_DRIVER] It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.

Stack Trace:
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 468, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_step.py", line 751, in _gen_fn
    gen_output = output_manager.handle_output(output_context, output.value)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/storage/upath_io_manager.py", line 446, in handle_output
    self.dump_to_path(context=context, obj=obj, path=path)
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/storage/fs_io_manager.py", line 260, in dump_to_path
    pickle.dump(obj, file, PICKLE_PROTOCOL)
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/context.py", line 466, in __getnewargs__
    raise PySparkRuntimeError(
[0m
