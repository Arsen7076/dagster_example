[32m2024-07-12 03:49:06 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 07e248e2-90bc-41f7-b082-5e08e3cc3882 - 71505 - LOGS_CAPTURED - Started capturing logs in process (pid: 71505).
[32m2024-07-12 03:49:06 +0400[0m - dagster - [34mDEBUG[0m - __ephemeral_asset_job__ - 07e248e2-90bc-41f7-b082-5e08e3cc3882 - 71505 - backfill_historical_data - STEP_START - Started execution of step "backfill_historical_data".
[32m2024-07-12 03:49:07 +0400[0m - dagster - [34mERROR[0m - [31m__ephemeral_asset_job__ - 07e248e2-90bc-41f7-b082-5e08e3cc3882 - 71505 - backfill_historical_data - STEP_FAILURE - Execution of step "backfill_historical_data" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "backfill_historical_data"::

AttributeError: 'NoneType' object has no attribute 'sc'

Stack Trace:
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 468, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 141, in _coerce_op_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 129, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/Desktop/ameria/v2/dagster_module/assets.py", line 41, in backfill_historical_data
    spark.stop()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/sql/session.py", line 1796, in stop
    self._sc.stop()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/context.py", line 666, in stop
    self._accumulatorServer.shutdown()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/accumulators.py", line 316, in shutdown
    SocketServer.TCPServer.shutdown(self)
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/socketserver.py", line 255, in shutdown
    self.__is_shut_down.wait()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/threading.py", line 655, in wait
    signaled = self._cond.wait(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "/home/user/anaconda3/envs/ameria/lib/python3.12/site-packages/pyspark/context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^
[0m
